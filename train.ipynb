{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfqzG-psHbd"
   },
   "source": [
    "#**Seq2seq Neural Machine Translation using LSTMs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##**Decoding with Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "upXa_erqyzKm"
   },
   "outputs": [],
   "source": [
    "# change this to the path to your folder. Remember to start from the home directory\n",
    "PATH = '/Users/alexandraspyrou/QueenMary/B_Semester/NN_and_NLP/Week_5/Lab_05_06/nmt_lab_files/'#'My Drive/GTA/nmt_lab_files/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "ffbGcgrRy7p6"
   },
   "outputs": [],
   "source": [
    "PATH_TO_FOLDER = PATH #\"/content/drive/\" + PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "XfSgKakK0QgV"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(PATH_TO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "NmSgv44y0TN9"
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = PATH_TO_FOLDER + 'data.30.vi'\n",
    "TARGET_PATH = PATH_TO_FOLDER + 'data.30.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model,Input\n",
    "\n",
    "from nmt_model_keras import load_dataset, NmtModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch 1/10\n",
      "240/240 [==============================] - 84s 349ms/step - loss: 1.4981 - accuracy: 0.3818\n",
      "Time used for epoch 1: 1 m 23 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "Model BLEU score: 4.83\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 101s 419ms/step - loss: 1.4651 - accuracy: 0.3871\n",
      "Time used for epoch 2: 1 m 40 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "Model BLEU score: 4.75\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 88s 366ms/step - loss: 1.4390 - accuracy: 0.3903\n",
      "Time used for epoch 3: 1 m 27 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "Model BLEU score: 4.99\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 86s 359ms/step - loss: 1.4172 - accuracy: 0.3935\n",
      "Time used for epoch 4: 1 m 26 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "Model BLEU score: 5.10\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 86s 360ms/step - loss: 1.3994 - accuracy: 0.3962\n",
      "Time used for epoch 5: 1 m 26 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "Model BLEU score: 5.20\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 1010s 4s/step - loss: 1.3837 - accuracy: 0.3987\n",
      "Time used for epoch 6: 16 m 50 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "Model BLEU score: 5.38\n",
      "Time used for evaluate on dev set: 0 m 14 s\n",
      "Starting training epoch 7/10\n",
      "240/240 [==============================] - 469s 2s/step - loss: 1.3697 - accuracy: 0.4009\n",
      "Time used for epoch 7: 7 m 49 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "Model BLEU score: 5.13\n",
      "Time used for evaluate on dev set: 0 m 6 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 75s 311ms/step - loss: 1.3583 - accuracy: 0.4025\n",
      "Time used for epoch 8: 1 m 14 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "Model BLEU score: 5.44\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 82s 343ms/step - loss: 1.3455 - accuracy: 0.4045\n",
      "Time used for epoch 9: 1 m 22 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "Model BLEU score: 5.54\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 85s 353ms/step - loss: 1.3371 - accuracy: 0.4057\n",
      "Time used for epoch 10: 1 m 24 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "Model BLEU score: 5.53\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Training finished!\n",
      "Time used for training: 37 m 27 s\n",
      "Evaluating on test set:\n",
      "Model BLEU score: 5.89\n",
      "Time used for evaluate on test set: 0 m 7 s\n"
     ]
    }
   ],
   "source": [
    "max_example = 30000\n",
    "use_attention = False\n",
    "\n",
    "print('loading dictionaries')\n",
    "train_data, dev_data, test_data, source_dict, target_dict = load_dataset(SOURCE_PATH, TARGET_PATH,\n",
    "                                                                         max_num_examples=max_example)\n",
    "print(\"read %d/%d/%d train/dev/test batches\" % (len(train_data[0]), len(dev_data[0]), len(test_data[0])))\n",
    "\n",
    "model = NmtModel(source_dict, target_dict, use_attention)\n",
    "model.build()\n",
    "model.train(train_data, dev_data, test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict.ids2words = {v:k for k, v in source_dict.word2ids.items()}\n",
    "target_dict.ids2words = {v:k for k, v in target_dict.word2ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tôi muốn nói với tất cả quý vị , và mời quý vị đến và xem rõ hơn . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 16\n",
    "\n",
    "\" \".join([source_dict.ids2words[x] for x in dev_data[0][sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to tell you , and we &apos;re talking about the <unk> , and it &apos;s <unk> .'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_trans = model.print([dev_data[0][sentence:sentence+1] ,dev_data[1][sentence:sentence+1]])[0]\n",
    "\" \".join([x for x in sentence_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsO7wW6U1w2m",
    "outputId": "c8dcfa85-47b9-4e54-ec5e-aeab46756e0f"
   },
   "outputs": [],
   "source": [
    "#nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nmt.get_target_sentences(SOURCE_PATH, TARGET_PATH, use_attention=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlMDC3DJi12c"
   },
   "source": [
    "##**Decoding with Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens in source: 2034, number of tokens in target:2506\n",
      "Task 1(a): Creating the embedding lookups...\n",
      "\n",
      "Task 1(b): Looking up source and target words...\n",
      "\n",
      "Task 1(c): Creating an encoder\n",
      "target_word_embd_drop shape =  (None, None, 100)\n",
      "B4\n",
      "(None, None, 200)\n",
      "(None, None, 200)\n",
      "(None, None, 400)\n",
      "After (None, None, 400)\n",
      "\t\t\t\t\t\t Train Model Summary.\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_126 (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, None, 100)    203400      input_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_127 (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, None, 100)    0           embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, None, 100)    250600      input_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_60 (LSTM)                  [(None, None, 200),  240800      dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, None, 100)    0           embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_61 (LSTM)                  [(None, None, 200),  240800      dropout_61[0][0]                 \n",
      "                                                                 lstm_60[0][1]                    \n",
      "                                                                 lstm_60[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_13 (AttentionLa (None, None, 400)    0           lstm_60[0][0]                    \n",
      "                                                                 lstm_61[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, None, 2506)   1004906     attention_layer_13[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,940,506\n",
      "Trainable params: 1,940,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_126 (InputLayer)       [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_60 (Embedding)     (None, None, 100)         203400    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               [(None, None, 200), (None 240800    \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " Putting together the decoder states\n",
      "(None, None, 400)\n",
      "\t\t\t\t\t\t Decoder Inference Model summary\n",
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_127 (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, None, 100)    250600      input_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_128 (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_129 (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_130 (InputLayer)          [(None, None, 200)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_61 (LSTM)                  [(None, None, 200),  240800      embedding_61[0][0]               \n",
      "                                                                 input_128[0][0]                  \n",
      "                                                                 input_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_14 (AttentionLa (None, None, 400)    0           input_130[0][0]                  \n",
      "                                                                 lstm_61[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, None, 2506)   1004906     attention_layer_14[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,496,306\n",
      "Trainable params: 1,496,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/10\n",
      "(100, 31, 400)\n",
      "(100, 31, 400)\n",
      "240/240 [==============================] - 202s 830ms/step - loss: 2.3391 - accuracy: 0.2092\n",
      "Time used for epoch 1: 3 m 21 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "(100, 1, 400)\n",
      "(100, 1, 400)\n",
      "Model BLEU score: 4.37\n",
      "Time used for evaluate on dev set: 0 m 18 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 220s 918ms/step - loss: 1.5955 - accuracy: 0.3906\n",
      "Time used for epoch 2: 3 m 40 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "Model BLEU score: 9.76\n",
      "Time used for evaluate on dev set: 0 m 18 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 1149s 5s/step - loss: 1.3348 - accuracy: 0.4520\n",
      "Time used for epoch 3: 19 m 8 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "Model BLEU score: 12.52\n",
      "Time used for evaluate on dev set: 0 m 19 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 277s 1s/step - loss: 1.1890 - accuracy: 0.4829\n",
      "Time used for epoch 4: 4 m 36 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "Model BLEU score: 13.29\n",
      "Time used for evaluate on dev set: 17 m 4 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 968s 4s/step - loss: 1.0979 - accuracy: 0.5028\n",
      "Time used for epoch 5: 16 m 7 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "Model BLEU score: 14.36\n",
      "Time used for evaluate on dev set: 0 m 17 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 242s 1s/step - loss: 1.0360 - accuracy: 0.5180\n",
      "Time used for epoch 6: 4 m 2 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "Model BLEU score: 14.65\n",
      "Time used for evaluate on dev set: 0 m 18 s\n",
      "Starting training epoch 7/10\n",
      "240/240 [==============================] - 485s 2s/step - loss: 0.9907 - accuracy: 0.5302\n",
      "Time used for epoch 7: 8 m 4 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "Model BLEU score: 14.75\n",
      "Time used for evaluate on dev set: 0 m 36 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 539s 2s/step - loss: 0.9554 - accuracy: 0.5401\n",
      "Time used for epoch 8: 8 m 58 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "Model BLEU score: 15.03\n",
      "Time used for evaluate on dev set: 0 m 36 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 555s 2s/step - loss: 0.9275 - accuracy: 0.5476\n",
      "Time used for epoch 9: 9 m 15 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "Model BLEU score: 14.63\n",
      "Time used for evaluate on dev set: 0 m 34 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 526s 2s/step - loss: 0.9023 - accuracy: 0.5544\n",
      "Time used for epoch 10: 8 m 45 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "Model BLEU score: 14.82\n",
      "Time used for evaluate on dev set: 0 m 34 s\n",
      "Training finished!\n",
      "Time used for training: 107 m 0 s\n",
      "Evaluating on test set:\n",
      "Model BLEU score: 15.26\n",
      "Time used for evaluate on test set: 0 m 34 s\n"
     ]
    }
   ],
   "source": [
    "max_example = 30000\n",
    "use_attention = True\n",
    "\n",
    "model_attention = NmtModel(source_dict, target_dict, use_attention)\n",
    "model_attention.build()\n",
    "model_attention.train(train_data, dev_data, test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict.ids2words = {v:k for k, v in source_dict.word2ids.items()}\n",
    "target_dict.ids2words = {v:k for k, v in target_dict.word2ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tôi muốn nói với tất cả quý vị , và mời quý vị đến và xem rõ hơn . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 16\n",
    "\n",
    "\" \".join([source_dict.ids2words[x] for x in dev_data[0][sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to talk to you , and you come to see and see it more or less .'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_trans = model_attention.print([dev_data[0][sentence:sentence+1] ,dev_data[1][sentence:sentence+1]])[0]\n",
    "\" \".join([x for x in sentence_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23t6wfpLkb2F",
    "outputId": "db7e09dc-f5da-4083-8ac8-89875e1b9fc8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries\n",
      "read 24000/3000/3000 train/dev/test batches\n",
      "number of tokens in source: 2034, number of tokens in target:2506\n",
      "Task 1(a): Creating the embedding lookups...\n",
      "\n",
      "Task 1(b): Looking up source and target words...\n",
      "\n",
      "Task 1(c): Creating an encoder\n",
      "target_word_embd_drop shape =  (None, None, 100)\n",
      "B4\n",
      "(None, None, 200)\n",
      "(None, None, 200)\n",
      "(None, None, 400)\n",
      "After (None, None, 400)\n",
      "\t\t\t\t\t\t Train Model Summary.\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, None, 100)    203400      input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, 100)    0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, None, 100)    250600      input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  [(None, None, 200),  240800      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, None, 100)    0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  [(None, None, 200),  240800      dropout_27[0][0]                 \n",
      "                                                                 lstm_26[0][1]                    \n",
      "                                                                 lstm_26[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_11 (AttentionLa (None, None, 400)    0           lstm_26[0][0]                    \n",
      "                                                                 lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 2506)   1004906     attention_layer_11[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,940,506\n",
      "Trainable params: 1,940,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_26 (Embedding)     (None, None, 100)         203400    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               [(None, None, 200), (None 240800    \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " Putting together the decoder states\n",
      "(None, None, 400)\n",
      "\t\t\t\t\t\t Decoder Inference Model summary\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, None, 100)    250600      input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           [(None, None, 200)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  [(None, None, 200),  240800      embedding_27[0][0]               \n",
      "                                                                 input_43[0][0]                   \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_12 (AttentionLa (None, None, 400)    0           input_45[0][0]                   \n",
      "                                                                 lstm_27[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 2506)   1004906     attention_layer_12[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,496,306\n",
      "Trainable params: 1,496,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/10\n",
      "(100, 31, 400)\n",
      "(100, 31, 400)\n",
      "240/240 [==============================] - 105s 428ms/step - loss: 2.3304 - accuracy: 0.2086\n",
      "Time used for epoch 1: 1 m 44 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "(100, 1, 400)\n",
      "(100, 1, 400)\n",
      "Model BLEU score: 4.38\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 112s 466ms/step - loss: 1.5767 - accuracy: 0.3967\n",
      "Time used for epoch 2: 1 m 51 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "Model BLEU score: 10.26\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 115s 477ms/step - loss: 1.3349 - accuracy: 0.4509\n",
      "Time used for epoch 3: 1 m 54 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "Model BLEU score: 12.52\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 120s 500ms/step - loss: 1.1942 - accuracy: 0.4798\n",
      "Time used for epoch 4: 1 m 59 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "Model BLEU score: 13.60\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 119s 495ms/step - loss: 1.1045 - accuracy: 0.5003\n",
      "Time used for epoch 5: 1 m 58 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "Model BLEU score: 14.40\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 121s 505ms/step - loss: 1.0427 - accuracy: 0.5158\n",
      "Time used for epoch 6: 2 m 1 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "Model BLEU score: 14.73\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 122s 510ms/step - loss: 0.9971 - accuracy: 0.5279\n",
      "Time used for epoch 7: 2 m 2 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "Model BLEU score: 14.65\n",
      "Time used for evaluate on dev set: 0 m 9 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 128s 534ms/step - loss: 0.9599 - accuracy: 0.5376\n",
      "Time used for epoch 8: 2 m 8 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "Model BLEU score: 14.88\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 122s 507ms/step - loss: 0.9296 - accuracy: 0.5460\n",
      "Time used for epoch 9: 2 m 1 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "Model BLEU score: 14.84\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 123s 511ms/step - loss: 0.9082 - accuracy: 0.5525\n",
      "Time used for epoch 10: 2 m 2 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "Model BLEU score: 14.94\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Training finished!\n",
      "Time used for training: 21 m 13 s\n",
      "Evaluating on test set:\n",
      "Model BLEU score: 15.79\n",
      "Time used for evaluate on test set: 0 m 8 s\n"
     ]
    }
   ],
   "source": [
    "#nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7001_2021_22_Lab5_6_NeuralMachineTranslation_studentEdition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
